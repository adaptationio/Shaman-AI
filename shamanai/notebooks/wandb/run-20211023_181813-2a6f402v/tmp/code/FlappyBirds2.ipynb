{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyautogui\n",
    "import imutils\n",
    "import cv2\n",
    "import pytesseract\n",
    "from pynput import mouse\n",
    "import time\n",
    "import easyocr\n",
    "import torch\n",
    "#from PIL import ImageGrab\n",
    "import pyscreenshot\n",
    "import pyscreenshot as ImageGrab\n",
    "#pytesseract.pytesseract.tesseract_cmd = r'C:\\Users\\adaptation\\anaconda3\\envs\\Shaman-AI\\Library\\bin\\tesseract.exe'\n",
    "from detecto import core, utils, visualize\n",
    "from detecto.visualize import show_labeled_image, plot_prediction_grid\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from detecto import utils as ut\n",
    "import optuna\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "from selenium import webdriver\n",
    "import cv2\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import csv\n",
    "import argparse\n",
    "from functools import partial\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "#options = webdriver.FirefoxOptions()\n",
    "#options.add_argument('--headless')\n",
    "#options.add_argument('--no-sandbox')\n",
    "#options.add_argument('--disable-dev-shm-usage')\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageProcess():\n",
    "    def __init__(self):\n",
    "        self.love = \"ramona\"\n",
    "        self.reader = easyocr.Reader(['en'])\n",
    "        #self.model = core.Model.load('model_weights.pth', ['bird', 'hole'])\n",
    "\n",
    "    def on_click(self, x, y, button, pressed):\n",
    "        if button == mouse.Button.left:\n",
    "            print('{} at {}'.format('Pressed Left Click' if pressed else 'Released Left Click', (x, y)))\n",
    "        \n",
    "            return False # Returning False if you need to stop the program when Left clicked.\n",
    "        else:\n",
    "            print('{} at {}'.format('Pressed Right Click' if pressed else 'Released Right Click', (x, y)))\n",
    "            return False # Returning False if you need to stop the program when Left clicked.\n",
    "\n",
    "    def get_position(self):\n",
    "        print(\"Please select top corner\")\n",
    "        listener = mouse.Listener(on_click=self.on_click)\n",
    "        listener.start()\n",
    "        listener.join()\n",
    "        X=pyautogui.position()\n",
    "        self.topx = X[0]\n",
    "        self.topy= X[1]\n",
    "        time.sleep(1)\n",
    "        print(self.topx)\n",
    "        print(self.topy)\n",
    "        print(\"Please select bottom corner\")\n",
    "        listener = mouse.Listener(on_click=self.on_click)\n",
    "        listener.start()\n",
    "        listener.join()\n",
    "        B=pyautogui.position()\n",
    "        self.bottomx = B[0]\n",
    "        self.bottomy= B[1]\n",
    "        print(self.bottomx)\n",
    "        print(self.bottomy)\n",
    "        return self.topx, self.topy, self.bottomx, self.bottomy\n",
    "\n",
    "    def object_detection(self):\n",
    "        state = ImageGrab.grab(bbox=(871, 186, 1227, 821), backend=\"mss\", childprocess=False)\n",
    "        #state= pyautogui.screenshot(region=(int(topx), int(topy), int(bottomx), int(bottomy)))\n",
    "        state = cv2.cvtColor(np.array(state), cv2.COLOR_RGB2GRAY)\n",
    "        state = cv2.cvtColor(state,cv2.COLOR_GRAY2RGB)\n",
    "        #state = np.array(state)\n",
    "        #cv2.imwrite('gray.jpg', state)\n",
    "        #state = ut.read_image(state) \n",
    "        #state= cv2.imread('gray.jpg')\n",
    "        image = state\n",
    "        predictions = self.model.predict(image)\n",
    "        labels, boxes, scores = predictions\n",
    "\n",
    "        thresh=0.80\n",
    "        filtered_indices=np.where(scores>thresh)\n",
    "        filtered_scores=scores[filtered_indices]\n",
    "        filtered_boxes=boxes[filtered_indices]\n",
    "        num_list = filtered_indices[0].tolist()\n",
    "        filtered_labels = [labels[i] for i in num_list]\n",
    "        #print(filtered_labels)\n",
    "        if len(filtered_labels) == 2:\n",
    "            if filtered_labels[0] == \"bird\":\n",
    "                bird = filtered_boxes[0]\n",
    "            else:\n",
    "                bird = [0,0,0,0]\n",
    "            if filtered_labels[1] == \"hole\":\n",
    "                hole = filtered_boxes[1]\n",
    "            else:\n",
    "                hole = [0,0,0,0]\n",
    "        else:\n",
    "            try:\n",
    "                bird = filtered_boxes[0]\n",
    "                hole = [0,0,0,0]\n",
    "\n",
    "            except:\n",
    "                bird = [0,0,0,0]\n",
    "                hole = [0,0,0,0]\n",
    "        \n",
    "\n",
    "        #u = np.concatenate((u), axis=None)\n",
    "        #m = np.concatenate((m), axis=None)\n",
    "        #c = np.concatenate((c), axis=None)\n",
    "        flattened = np.concatenate((bird, hole), axis=None)\n",
    "        #print(flattened)\n",
    "        return flattened\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def image_ocr(self):\n",
    "        topx = self.topx\n",
    "        topy = self.topy\n",
    "        bottomx = self.bottomx - topx\n",
    "        bottomy =  self.bottomy - topy\n",
    "        state= pyautogui.screenshot(region=(int(topx), int(topy), int(bottomx), int(bottomy)))\n",
    "        #state = cv2.cvtColor(np.array(state), cv2.COLOR_BGR2GRAY)\n",
    "        state = cv2.cvtColor(np.array(state), cv2.COLOR_RGB2BGR)\n",
    "        #cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        text = pytesseract.image_to_string(state)\n",
    "        print(text)\n",
    "        return text\n",
    "\n",
    "    def easy_ocr(self):\n",
    "        topx = self.topx\n",
    "        topy = self.topy\n",
    "        bottomx = self.bottomx - topx\n",
    "        bottomy =  self.bottomy - topy\n",
    "        state= pyautogui.screenshot(region=(int(topx), int(topy), int(bottomx), int(bottomy)))\n",
    "        state = cv2.cvtColor(np.array(state), cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "\n",
    "        #state = 255 - cv2.threshold(state, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "        # Blur and perform text extraction\n",
    "        #state = cv2.GaussianBlur(state, (3,3), 0)\n",
    "        #self.reader = easyocr.Reader(['en'])\n",
    "        result = self.reader.readtext(state)\n",
    "        return result\n",
    "    \n",
    "  \n",
    "    \n",
    "    def game_start(self,tx, ty, bx, by):\n",
    "        topx = tx\n",
    "        topy = ty\n",
    "        bottomx = bx - topx\n",
    "        bottomy = by - topy\n",
    "        state= pyautogui.screenshot(region=(int(topx), int(topy), int(bottomx), int(bottomy)))\n",
    "        state = cv2.cvtColor(np.array(state), cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        \n",
    "\n",
    "        #state = 255 - cv2.threshold(state, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "        # Blur and perform text extraction\n",
    "        #state = cv2.GaussianBlur(state, (3,3), 0)\n",
    "        #self.reader = easyocr.Reader(['en'])\n",
    "        result = self.reader.readtext(state)\n",
    "        print(result)\n",
    "        if len(result) == 1:\n",
    "\n",
    "            print(result[0][1])\n",
    "            if result[0][1] == \"RESTART\":\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def game_start_2(self,tx, ty, bx, by, a):\n",
    "        topx = tx\n",
    "        topy = ty\n",
    "        bottomx = bx - topx\n",
    "        bottomy = by - topy\n",
    "        #state= pyautogui.screenshot(region=(int(topx), int(topy), int(bottomx), int(bottomy)))\n",
    "        state = ImageGrab.grab(bbox=(955, 391, 1019, 406), backend=\"mss\", childprocess=False)\n",
    "        b = cv2.cvtColor(np.array(state), cv2.COLOR_RGB2BGR)\n",
    "        difference = cv2.subtract(a, b)    \n",
    "        result = not np.any(difference)\n",
    "        if result is True:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def game_start_selenium(self,b, a):\n",
    "        \n",
    "        difference = cv2.subtract(a, b)    \n",
    "        result = not np.any(difference)\n",
    "        if result is True:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def game_start_make(self,tx, ty, bx, by):\n",
    "        topx = tx\n",
    "        topy = ty\n",
    "        bottomx = bx - topx\n",
    "        bottomy = by - topy\n",
    "        state= pyautogui.screenshot(region=(int(topx), int(topy), int(bottomx), int(bottomy)))\n",
    "        state = cv2.cvtColor(np.array(state), cv2.COLOR_RGB2BGR)\n",
    "        np.save('games_start.npy', state)\n",
    "        return state\n",
    "\n",
    "\n",
    "    def get_state(self,tx, ty, bx, by):\n",
    "        topx = tx\n",
    "        topy = ty\n",
    "        bottomx = bx - topx\n",
    "        bottomy = by - topy\n",
    "        state = ImageGrab.grab(bbox=(753, 186, 1227, 821), backend=\"mss\", childprocess=False)\n",
    "        #state= pyautogui.screenshot(region=(int(topx), int(topy), int(bottomx), int(bottomy)))\n",
    "        state = cv2.cvtColor(np.array(state), cv2.COLOR_RGB2GRAY)[..., np.newaxis]\n",
    "        \n",
    "        state= cv2.resize(state, (84, 84), interpolation=cv2.INTER_AREA)[..., np.newaxis]\n",
    "        #cv2.imwrite('red.jpg', state)\n",
    "        #state = torch.from_numpy(state)\n",
    "        #state = state.unsqueeze(dim=0)\n",
    "        return state\n",
    "\n",
    "    def get_state_save(self,tx, ty, bx, by, count, epoc):\n",
    "        count = count\n",
    "        epoc = epoc\n",
    "        topx = tx\n",
    "        topy = ty\n",
    "        bottomx = bx - topx\n",
    "        bottomy = by - topy\n",
    "        state = ImageGrab.grab(bbox=(871, 186, 1227, 821), backend=\"mss\", childprocess=False)\n",
    "        #state= pyautogui.screenshot(region=(int(topx), int(topy), int(bottomx), int(bottomy)))\n",
    "        state = cv2.cvtColor(np.array(state), cv2.COLOR_RGB2GRAY)[..., np.newaxis]\n",
    "        \n",
    "        #state= cv2.resize(state, (84, 84), interpolation=cv2.INTER_AREA)[..., np.newaxis]\n",
    "        cv2.imwrite('images/flappy/state'+str(count)+str(epoc)+'.jpeg', state)\n",
    "        #state = torch.from_numpy(state)\n",
    "        #state = state.unsqueeze(dim=0)\n",
    "        return state\n",
    "    \n",
    "    def get_state_test(self,tx, ty, bx, by):\n",
    "        topx = tx\n",
    "        topy = ty\n",
    "        bottomx = bx - topx\n",
    "        bottomy = by - topy\n",
    "        state= pyautogui.screenshot(region=(int(topx), int(topy), int(bottomx), int(bottomy)))\n",
    "        state = cv2.cvtColor(np.array(state), cv2.COLOR_RGB2GRAY)[..., np.newaxis]\n",
    "        state2= pyautogui.screenshot(region=(int(topx), int(topy), int(bottomx), int(bottomy)))\n",
    "        state2 = cv2.cvtColor(np.array(state2), cv2.COLOR_RGB2GRAY)[..., np.newaxis]\n",
    "        state3= pyautogui.screenshot(region=(int(topx), int(topy), int(bottomx), int(bottomy)))\n",
    "        state3 = cv2.cvtColor(np.array(state3), cv2.COLOR_RGB2GRAY)[..., np.newaxis]\n",
    "        state4= pyautogui.screenshot(region=(int(topx), int(topy), int(bottomx), int(bottomy)))\n",
    "        state4 = cv2.cvtColor(np.array(state4), cv2.COLOR_RGB2GRAY)[..., np.newaxis]\n",
    "        #vis = np.concatenate((state, state2, state3, state4), axis=1)\n",
    "        vis = np.stack((state, state2, state3, state4))\n",
    "        #state= cv2.resize(state, (84, 84), interpolation=cv2.INTER_AREA)\n",
    "        #state = torch.from_numpy(state)\n",
    "        #state = state.unsqueeze(dim=0)\n",
    "        return vis\n",
    "\n",
    "    def get_reward(self,tx, ty, bx, by):\n",
    "        topx = tx\n",
    "        topy = ty\n",
    "        bottomx = bx - topx\n",
    "        bottomy = by - topy\n",
    "        state= pyautogui.screenshot(region=(int(topx), int(topy), int(bottomx), int(bottomy)))\n",
    "        state = cv2.cvtColor(np.array(state), cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        \n",
    "\n",
    "        #state = 255 - cv2.threshold(state, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "        # Blur and perform text extraction\n",
    "        #state = cv2.GaussianBlur(state, (3,3), 0)\n",
    "        #self.reader = easyocr.Reader(['en'])\n",
    "        result = self.reader.readtext(state)\n",
    "    \n",
    "        print(result)\n",
    "        if len(result) == 1:\n",
    "\n",
    "            return int(0)\n",
    "        if len(result) == 2:\n",
    "                if result[1][1] == \"I\": \n",
    "                    return int(1)\n",
    "                elif result[1][1] == \"2\":\n",
    "                    return int(2)\n",
    "                elif result[1][1] == \"8\":\n",
    "                    return int(3)\n",
    "                else:\n",
    "                    return(4)\n",
    "        else:\n",
    "            return int(0)\n",
    "        \n",
    "    def image_ocr_2(self):\n",
    "        topx = self.topx\n",
    "        topy = self.topy\n",
    "        bottomx = self.bottomx - topx\n",
    "        bottomy =  self.bottomy - topy\n",
    "        custom_config = r'--oem 3 --psm 10'\n",
    "        image = pyautogui.screenshot(region=(int(topx), int(topy), int(bottomx), int(bottomy)))\n",
    "        gray= cv2.cvtColor(np.array(image), cv2.COLOR_BGR2GRAY)\n",
    "        thresh = 255 - cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "        # Blur and perform text extraction\n",
    "        thresh = cv2.GaussianBlur(thresh, (3,3), 0)\n",
    "        text = pytesseract.image_to_string(thresh, config=custom_config)\n",
    "        print(text)\n",
    "        return text\n",
    "\n",
    "    def image_stream(self):\n",
    "        topx = self.topx\n",
    "        topy = self.topy\n",
    "        bottomx = self.bottomx - topx\n",
    "        bottomy =  self.bottomy - topy \n",
    "        while True:\n",
    "            try:\n",
    "                state= pyautogui.screenshot(region=(int(topx), int(topy), int(bottomx), int(bottomy)))\n",
    "                state = cv2.cvtColor(np.array(state), cv2.COLOR_RGB2BGR)\n",
    "                cv2.imshow(\"Stream\", state)\n",
    "                if cv2.waitKey(1)& 0xFF == ord('q'):\n",
    "                    break      \n",
    "            except KeyboardInterrupt:\n",
    "                cv2.destroyAllWindows()\n",
    "                break\n",
    "\n",
    "    def get_image(self, ):\n",
    "        topx = self.topx\n",
    "        topy = self.topy\n",
    "        bottomx = self.bottomx - topx\n",
    "        bottomy =  self.bottomy - topy\n",
    "        state= pyautogui.screenshot(region=(int(topx), int(topy), int(bottomx), int(bottomy)))\n",
    "        state = cv2.cvtColor(np.array(state), cv2.COLOR_RGB2BGR)\n",
    "        return state\n",
    "\n",
    "    def check_image(self, a, b):\n",
    "        difference = cv2.subtract(a, b)    \n",
    "        result = not np.any(difference)\n",
    "        if result is True:\n",
    "            print(\"Pictures are the same\")\n",
    "        else:\n",
    "            print(\"Pictures are different\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_100281/1577047333.py:9: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  element = browser.find_element_by_id(\"testCanvas\")\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "browser = webdriver.Chrome()\n",
    "#browser = webdriver.Firefox(executable_path=\"./drivers/geckodriver\")\n",
    "browser.get(\"https://flappybird.io/\")\n",
    "element = browser.find_element_by_id(\"testCanvas\")\n",
    "time.sleep(5)\n",
    "element.click()\n",
    "time.sleep(2)\n",
    "\n",
    "# Element to be saved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_100281/288855981.py:1: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  element = browser.find_element_by_id(\"testCanvas\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element = browser.find_element_by_id(\"testCanvas\")\n",
    "png = browser.get_screenshot_as_png()\n",
    "location = element.location\n",
    "size  = element.size\n",
    "\n",
    "nparr = np.frombuffer(png, np.uint8)\n",
    "img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "\n",
    "\n",
    "left = location['x']\n",
    "top = location['y']\n",
    "right = location['x'] + size['width']\n",
    "bottom = location['y'] + size['height']\n",
    "\n",
    "#im = img[left:right, top:bottom]\n",
    "im = img[460:int(470), 170:int(180)]\n",
    "#im = img[440:int(445), 500:int(505)]\n",
    "im = np.array(im)\n",
    "        \n",
    "#im = cv2.resize(im, (84, 84), interpolation=cv2.INTER_AREA)[..., np.newaxis]\n",
    "cv2.imwrite('filename.png',im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlappyBirds2Env():\n",
    "    def __init__(self):\n",
    "        self.love = 14\n",
    "        self.actions = [0,1]\n",
    "        self.state = None\n",
    "        self.count = 0\n",
    "        self.load = True\n",
    "        self.eval = False\n",
    "        self.browser = webdriver.Chrome('chromedriver',options=options)\n",
    "        #self.browser = webdriver.Firefox(executable_path=\"./drivers/geckodriver\",options=options)\n",
    "        #self.browser = webdriver.Firefox(executable_path=\"./drivers/geckodriver\")\n",
    "        #self.browser = webdriver.Chrome() \n",
    "        self.browser.get(\"https://flappybird.io/\")\n",
    "\n",
    "# Element to be saved\n",
    "        self.element = self.browser.find_element(By.ID,'testCanvas')\n",
    "\n",
    "\n",
    "        time.sleep(5)\n",
    "        self.element.click()\n",
    "        time.sleep(2)\n",
    "        self.image_pro = ImageProcess()\n",
    "        self.frame = []\n",
    "        #self.game_start = np.load('games_start.npy')\n",
    "        #self.game_start2 = pyautogui.pixel(1029, 486)\n",
    "        #self.game_start = ImageGrab.grab(bbox=(955, 391, 1019, 406), backend=\"mss\", childprocess=False)\n",
    "        #self.game_start = cv2.cvtColor(np.array(self.game_start), cv2.COLOR_RGB2BGR)\n",
    "        self.game_start = self.selenium_start()\n",
    "        self.total_reward = 0\n",
    "        self.epoc = 0\n",
    "        #self.emark = (1029, 486)\n",
    "        #self.pixel = (self.emark[0]-1, self.emark[1]-1, self.emark[0]+1, self.emark[1]+1)\n",
    "        #self.original_pixel_color = ImageGrab.grab(self.pixel).getpixel((0,0))\n",
    "\n",
    "    def selenium_grab(self):\n",
    "        png = self.browser.get_screenshot_as_png()\n",
    "        location = self.element.location\n",
    "        size  = self.element.size\n",
    "\n",
    "        nparr = np.frombuffer(png, np.uint8)\n",
    "        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "\n",
    "\n",
    "        left = location['x']\n",
    "        top = location['y']\n",
    "        right = location['x'] + size['width']\n",
    "        bottom = location['y'] + size['height']\n",
    "\n",
    "        #im = img[left:right, top:bottom]\n",
    "        im = img[top:int(bottom), left:int(right)]\n",
    "        im = cv2.cvtColor(np.array(im), cv2.COLOR_RGB2GRAY)[..., np.newaxis]\n",
    "        \n",
    "        im = cv2.resize(im, (84, 84), interpolation=cv2.INTER_AREA)[..., np.newaxis]\n",
    "        return im\n",
    "\n",
    "    def selenium_start(self):\n",
    "        element = self.browser.find_element_by_id(\"testCanvas\")\n",
    "        png = self.browser.get_screenshot_as_png()\n",
    "        location = element.location\n",
    "        size  = element.size\n",
    "\n",
    "        nparr = np.frombuffer(png, np.uint8)\n",
    "        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "\n",
    "\n",
    "        left = location['x']\n",
    "        top = location['y']\n",
    "        right = location['x'] + size['width']\n",
    "        bottom = location['y'] + size['height']\n",
    "\n",
    "        #im = img[left:right, top:bottom]\n",
    "        #im = img[top:int(bottom), left:int(right)]\n",
    "        im = img[460:int(470), 170:int(180)]\n",
    "        #im = img[460:int(470), 560:int(580)]\n",
    "        #im = img[440:int(445), 500:int(505)]\n",
    "        im = np.array(im)\n",
    "        #im = cv2.resize(im, (84, 84), interpolation=cv2.INTER_AREA)[..., np.newaxis]\n",
    "        cv2.imwrite('filename.png',im)\n",
    "        return im\n",
    "\n",
    "    def selenium_end(self):\n",
    "        png = self.browser.get_screenshot_as_png()\n",
    "        location = self.element.location\n",
    "        size  = self.element.size\n",
    "\n",
    "        nparr = np.frombuffer(png, np.uint8)\n",
    "        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "\n",
    "\n",
    "        left = location['x']\n",
    "        top = location['y']\n",
    "        right = location['x'] + size['width']\n",
    "        bottom = location['y'] + size['height']\n",
    "\n",
    "        #im = img[left:right, top:bottom]\n",
    "        #im = img[top:int(bottom), left:int(right)]\n",
    "        im = img[460:int(416), 170:int(179)]\n",
    "        im = cv2.cvtColor(np.array(im), cv2.COLOR_RGB2GRAY)\n",
    "        #im = cv2.resize(im, (84, 84), interpolation=cv2.INTER_AREA)[..., np.newaxis]\n",
    "        cv2.imwrite('filename.png',im)\n",
    "        return im\n",
    "\n",
    "    def controller(self):\n",
    "        jack = \"mose\"\n",
    "    \n",
    "    def state_maker(self):\n",
    "        #frame = self.image_pro.get_state(752, 188, 1228, 823)\n",
    "        frame = self.selenium_grab()\n",
    "        #self.frame.insert(0, frame)\n",
    "        #elf.frame.pop()\n",
    "        #state = np.stack((self.frame[0], self.frame[1], self.frame[2], self.frame[3]))\n",
    "        return frame\n",
    "\n",
    "    def state_maker_start(self):\n",
    "        frame = self.image_pro.get_state(752, 188, 1228, 823)\n",
    "        \n",
    "        #self.frame.pop()\n",
    "        return frame\n",
    "\n",
    "    \n",
    "        \n",
    "        rame2 = self.image_pro.get_state(752, 188, 1228, 823)\n",
    "        frame3 = self.image_pro.get_state(752, 188, 1228, 823)\n",
    "        frame4 = self.image_pro.get_state(752, 188, 1228, 823)\n",
    "        self.frame.insert(3, frame)\n",
    "        self.frame.insert(2, frame2)\n",
    "        self.frame.insert(1, frame3)\n",
    "        self.frame.insert(0, frame4)\n",
    "        state = np.stack((self.frame[0], self.frame[1], self.frame[2], self.frame[3]))\n",
    "\n",
    "    def timer2(self):\n",
    "        timeout = time.time() + 0.1   # 5 minutes from now\n",
    "        while True:\n",
    "            test = 0\n",
    "            if test == 5 or time.time() > timeout:\n",
    "                break\n",
    "            test = test - 1\n",
    "\n",
    "    def timer(self):\n",
    "        timeout = time.time() + 0.325   # 5 minutes from now\n",
    "        while True:\n",
    "            test = 0\n",
    "            if test == 5 or time.time() > timeout:\n",
    "                break\n",
    "            test = test - 1\n",
    "        \n",
    "\n",
    "    def step(self, action):\n",
    "        self.count += 1\n",
    "        \n",
    "        done = self.check_start()\n",
    "        if done == True:\n",
    "            print(\"done\")\n",
    "        else:\n",
    "            if action == 1:\n",
    "                self.element.click()\n",
    "                #ActionChains(self.browser).send_keys(Keys.SPACE).perform()\n",
    "                #pyautogui.click(x=795, y= 219, button='left')\n",
    "                #self.rewards = self.rewards - 0.01\n",
    "            else:\n",
    "                d=1\n",
    "        #self.player.action(self.action)\n",
    "        #self.timer2()\n",
    "        #time.sleep(0.1)\n",
    "        state = self.state_maker()\n",
    "        #self.image_pro.get_state_save(752, 188, 1228, 823, self.count, self.epoc)\n",
    "        self.state = state\n",
    "        #state = self.image_pro.object_detection()\n",
    "        \n",
    "        self.rewards = self.count / 100\n",
    "        self.total_reward = self.total_reward + self.rewards\n",
    "        \n",
    "        #reward = self.reward(self.get_state(), self.bet_value)\n",
    "        #self.player.balance += reward\n",
    "        remainder = self.count % 1\n",
    "        #is_divisible = remainder == 0\n",
    "        #if is_divisible == True:\n",
    "        if done == False:\n",
    "\n",
    "            done = self.check_start()\n",
    "\n",
    "        #if self.count == 100:\n",
    "            #done = True\n",
    "        if done == True:\n",
    "            #self.rewards = self.rewards\n",
    "            self.total_reward = self.total_reward + self.rewards\n",
    "            print(self.count)\n",
    "            print(self.epoc)\n",
    "            \n",
    "            \n",
    "        #time.sleep(0.1)\n",
    "        \n",
    "        return state, self.rewards, done\n",
    "\n",
    "    def check_start(self):\n",
    "        #check = self.image_pro.game_start_2(955, 391, 1019, 406, self.game_start)\n",
    "        check = self.image_pro.game_start_selenium(self.selenium_start(), self.game_start)\n",
    "        #check = pyautogui.pixelMatchesColor(1029, 486,(222, 216, 149))\n",
    "        #self.new_pixel_color = ImageGrab.grab(pixel).getpixel((0,0))\n",
    "        #check = self.new_pixel_color == self.original_pixel_color\n",
    "        return check\n",
    "\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        \n",
    "        self.total_reward = 0\n",
    "        #self.player.balance = 0\n",
    "        self.count = 0\n",
    "        self.epoc += 1\n",
    "        remainder = self.epoc % 100\n",
    "        is_divisible = remainder == 0\n",
    "        if is_divisible == True:\n",
    "            self.browser.quit()\n",
    "            self.browser = webdriver.Chrome('chromedriver',options=options)\n",
    "            #self.browser = webdriver.Firefox(executable_path=\"./drivers/geckodriver\",options=options)\n",
    "            #self.browser = webdriver.Firefox(executable_path=\"./drivers/geckodriver\")\n",
    "            #self.browser = webdriver.Chrome() \n",
    "            self.browser.get(\"https://flappybird.io/\")\n",
    "\n",
    "            # Element to be saved\n",
    "            self.element = self.browser.find_element(By.ID,'testCanvas')\n",
    "            time.sleep(2)\n",
    "            self.element.click()\n",
    "            time.sleep(2)\n",
    "            print(\"chrome started\")\n",
    "        for i in range(10):\n",
    "            start = self.check_start()\n",
    "            if start == True:\n",
    "                ActionChains(self.browser).send_keys(Keys.SPACE).perform()\n",
    "                #self.element.click()\n",
    "                #pyautogui.click(x=914, y=566, button='left')\n",
    "                #print(\"start\")\n",
    "                break\n",
    "            else:\n",
    "                print(\"no reset\")\n",
    "\n",
    "        #self.make_episode()\n",
    "        \n",
    "        #print(len(self.state))\n",
    "        #self.timer()\n",
    "        #time.sleep(1)\n",
    "        #ActionChains(self.browser).send_keys(Keys.SPACE).perform()\n",
    "        #self.element.click()\n",
    "        #self.timer()\n",
    "        #time.sleep(1)\n",
    "        #self.element.click()\n",
    "        #self.timer()\n",
    "        #time.sleep(1)\n",
    "        #self.element.click()\n",
    "        #self.timer()\n",
    "        #time.sleep(1)\n",
    "        #self.element.click()\n",
    "        #self.timer()\n",
    "        #time.sleep(1)\n",
    "        #self.element.click()\n",
    "        #self.timer()\n",
    "        #time.sleep(1)\n",
    "        #self.element.click()\n",
    "        #self.timer()\n",
    "        #time.sleep(1)\n",
    "        #self.element.click()\n",
    "        #time.sleep(.5)\n",
    "        #self.element.click()\n",
    "        #time.sleep(.5)\n",
    "        #self.element.click()\n",
    "        #time.sleep(.5)\n",
    "        #self.element.click()\n",
    "        #time.sleep(.5)\n",
    "        #self.element.click()\n",
    "        #time.sleep(.5)\n",
    "        #self.element.click()\n",
    "        #time.sleep(.5)\n",
    "        #self.element.click()\n",
    "        \n",
    "        \n",
    "        \n",
    "        state = self.state_maker()\n",
    "        #state = self.image_pro.object_detection()\n",
    "        self.rewards = 0\n",
    "        return state\n",
    "\n",
    "    def render(self):\n",
    "        print(self.player.balance)\n",
    "\n",
    "    def reward(self, state):\n",
    "        reward = 0\n",
    "    \n",
    "\n",
    "        return reward\n",
    "    \n",
    "    def done(self, count):\n",
    "        if count == 10000:\n",
    "            \n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def start(self):\n",
    "        self.something = \"lala\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlappyBirdsEnv():\n",
    "    def __init__(self):\n",
    "        self.love = 14\n",
    "        self.actions = [0,1]\n",
    "        self.state = None\n",
    "        self.count = 0\n",
    "        self.load = True\n",
    "        self.eval = False\n",
    "        self.image_pro = ImageProcess()\n",
    "        self.frame = []\n",
    "        #self.game_start = np.load('games_start.npy')\n",
    "        #self.game_start2 = pyautogui.pixel(1029, 486)\n",
    "        self.game_start = ImageGrab.grab(bbox=(955, 391, 1019, 406), backend=\"mss\", childprocess=False)\n",
    "        self.game_start = cv2.cvtColor(np.array(self.game_start), cv2.COLOR_RGB2BGR)\n",
    "        self.total_reward = 0\n",
    "        self.epoc = 0\n",
    "        #self.emark = (1029, 486)\n",
    "        #self.pixel = (self.emark[0]-1, self.emark[1]-1, self.emark[0]+1, self.emark[1]+1)\n",
    "        #self.original_pixel_color = ImageGrab.grab(self.pixel).getpixel((0,0))\n",
    "\n",
    "    def controller(self):\n",
    "        jack = \"mose\"\n",
    "    \n",
    "    def state_maker(self):\n",
    "        frame = self.image_pro.get_state(752, 188, 1228, 823)\n",
    "        #self.frame.insert(0, frame)\n",
    "        #elf.frame.pop()\n",
    "        #state = np.stack((self.frame[0], self.frame[1], self.frame[2], self.frame[3]))\n",
    "        return frame\n",
    "\n",
    "    def state_maker_start(self):\n",
    "        frame = self.image_pro.get_state(752, 188, 1228, 823)\n",
    "        \n",
    "        #self.frame.pop()\n",
    "        return frame\n",
    "\n",
    "    \n",
    "        \n",
    "        rame2 = self.image_pro.get_state(752, 188, 1228, 823)\n",
    "        frame3 = self.image_pro.get_state(752, 188, 1228, 823)\n",
    "        frame4 = self.image_pro.get_state(752, 188, 1228, 823)\n",
    "        self.frame.insert(3, frame)\n",
    "        self.frame.insert(2, frame2)\n",
    "        self.frame.insert(1, frame3)\n",
    "        self.frame.insert(0, frame4)\n",
    "        state = np.stack((self.frame[0], self.frame[1], self.frame[2], self.frame[3]))\n",
    "        \n",
    "\n",
    "    def step(self, action):\n",
    "        \n",
    "        self.count += 1\n",
    "        if action == 1:\n",
    "            pyautogui.click(x=795, y= 219, button='left')\n",
    "            #self.rewards = self.rewards - 0.01\n",
    "        else:\n",
    "            d=1\n",
    "        #self.player.action(self.action)\n",
    "        time.sleep(0.1)\n",
    "        state = self.state_maker()\n",
    "        #self.image_pro.get_state_save(752, 188, 1228, 823, self.count, self.epoc)\n",
    "        self.state = state\n",
    "        #state = self.image_pro.object_detection()\n",
    "        \n",
    "        self.rewards = self.count / 100\n",
    "        self.total_reward = self.total_reward + self.rewards\n",
    "        \n",
    "        #reward = self.reward(self.get_state(), self.bet_value)\n",
    "        #self.player.balance += reward\n",
    "        remainder = self.count % 1\n",
    "        is_divisible = remainder == 0\n",
    "        if is_divisible == True:\n",
    "            done = self.check_start()\n",
    "\n",
    "        else:\n",
    "            done = False\n",
    "        if self.count == 100:\n",
    "            done = True\n",
    "        if done == True:\n",
    "            #self.rewards = self.rewards\n",
    "            self.total_reward = self.total_reward + self.rewards\n",
    "            print(self.count)\n",
    "            print(self.epoc)\n",
    "            \n",
    "        #time.sleep(0.1)\n",
    "        \n",
    "        return state, self.rewards, done\n",
    "\n",
    "    def check_start(self):\n",
    "        check = self.image_pro.game_start_2(955, 391, 1019, 406, self.game_start)\n",
    "        #check = pyautogui.pixelMatchesColor(1029, 486,(222, 216, 149))\n",
    "        #self.new_pixel_color = ImageGrab.grab(pixel).getpixel((0,0))\n",
    "        #check = self.new_pixel_color == self.original_pixel_color\n",
    "        return check\n",
    "\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        \n",
    "        self.total_reward = 0\n",
    "        #self.player.balance = 0\n",
    "        self.count = 0\n",
    "        self.epoc += 1\n",
    "        remainder = self.epoc % 50\n",
    "        is_divisible = remainder == 0\n",
    "        if is_divisible == True:\n",
    "            time.sleep(20)\n",
    "            print(\"20 started\")\n",
    "        for i in range(10000):\n",
    "            start = self.check_start()\n",
    "            if start == True:\n",
    "                pyautogui.click(x=914, y=566, button='left')\n",
    "                print(\"start\")\n",
    "                break\n",
    "            else:\n",
    "                time.sleep(3)\n",
    "\n",
    "        #self.make_episode()\n",
    "        \n",
    "        #print(len(self.state))\n",
    "        time.sleep(1)\n",
    "        pyautogui.click(x=795, y= 219, button='left')\n",
    "        time.sleep(.425)\n",
    "        pyautogui.click(x=795, y= 219, button='left')\n",
    "        time.sleep(.425)\n",
    "        pyautogui.click(x=795, y= 219, button='left')\n",
    "        time.sleep(.425)\n",
    "        pyautogui.click(x=795, y= 219, button='left')\n",
    "        time.sleep(.425)\n",
    "        pyautogui.click(x=795, y= 219, button='left')\n",
    "        time.sleep(.425)\n",
    "        pyautogui.click(x=795, y= 219, button='left')\n",
    "        time.sleep(.425)\n",
    "        pyautogui.click(x=795, y= 219, button='left')\n",
    "        \n",
    "        \n",
    "        \n",
    "        state = self.state_maker()\n",
    "        #state = self.image_pro.object_detection()\n",
    "        self.rewards = 0\n",
    "        return state\n",
    "\n",
    "    def render(self):\n",
    "        print(self.player.balance)\n",
    "\n",
    "    def reward(self, state):\n",
    "        reward = 0\n",
    "    \n",
    "\n",
    "        return reward\n",
    "    \n",
    "    def done(self, count):\n",
    "        if count == 10000:\n",
    "            \n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def start(self):\n",
    "        self.something = \"lala\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#from .state import *\n",
    "import gym\n",
    "from gym import error, spaces, utils\n",
    "from gym.utils import seeding\n",
    "import numpy as np\n",
    "\n",
    "#MAIN WRAPPER FOR THE ENVIRONMENT TO WORK WITH OPEN AI GYM\n",
    "\n",
    "class Template_Gym(gym.Env):\n",
    "    metadata = {\n",
    "        \"render.modes\": [\"human\", \"rgb_array\"],\n",
    "    }\n",
    "    #Define Actions\n",
    "    ACTION = [0,1]\n",
    "\n",
    "    def __init__(self):\n",
    "        #self.config = config\n",
    "        #self.eval= self.config.eval\n",
    "        self.start = 0\n",
    "        self.env = FlappyBirds2Env()\n",
    "        self.viewer = None\n",
    "        self.info = None\n",
    "        self.reward = 0\n",
    "        self.done = False\n",
    "        self.state = None\n",
    "        self.action_dim = 4\n",
    "        self.state_dim = 32\n",
    "        self.num_envs = 1\n",
    "        self.num_envs_per_sub_batch = 1\n",
    "        self.starter = 0\n",
    "        self.discrete = True\n",
    "        \n",
    "        #self.shape = len(self.env.reset())\n",
    "        #print(self.shape)\n",
    "        #self.action_shape = len(self.env.actions)\n",
    "\n",
    "\n",
    "        #self.df = df\n",
    "        #self.reward_range = (0, MAX_ACCOUNT_BAL2NCE) \n",
    "        if self.discrete:\n",
    "            # forward or backward in each dimension\n",
    "            self.action_space = spaces.Discrete(2)\n",
    "            #self.action_space = spaces.Box(low=np.array([0, 0]), high=np.array([1, 1]), dtype=np.float32)\n",
    "\n",
    "            # observation is the x, y coordinate of the grid\n",
    "            #low = np.zeros(0, dtype=int)\n",
    "            #high =  np.array(1, dtype=int) - np.ones(len(self.maze_size), dtype=int)\n",
    "            #aud = 3339\n",
    "            #self.observation_space = spaces.Box(low=-10000, high=10000, shape=(3333,))\n",
    "            self.observation_space = spaces.Box(low=0, high=255,shape=(84,84,1), dtype=np.uint8)\n",
    "            #self.observation_space = spaces.Box(low=0, high=255, shape=(8,))\n",
    "        else:\n",
    "            # Actions of the format Buy x%, Sell x%, Hold, etc.\n",
    "            self.action_space = spaces.Box(low=np.array([0, 0]), high=np.array([3, 1]), dtype=np.float32)\n",
    "            #or\n",
    "            #self.action_space = spaces.Box(low=np.array([0, 0, 0, 0]), high=np.array([3, 1, 1, 1]), dtype=np.float16)\n",
    "\n",
    "\n",
    "            # Prices contains the OHCL values for the last five prices\n",
    "            self.observation_space = spaces.Box(low=0, high=1, shape=(6, 6), dtype=np.float16)\n",
    "\n",
    "        \n",
    "\n",
    "        # initial condition\n",
    "        #self.state = self.env.generate_number()\n",
    "        self.steps_beyond_done = None\n",
    "\n",
    "        # Simulation related variables.\n",
    "        self.seed()\n",
    "        #self.reset()\n",
    "\n",
    "        # Just need to initialize the relevant attributes\n",
    "        self.configure()\n",
    "\n",
    "    def __del__(self):\n",
    "        pass\n",
    "\n",
    "    def configure(self, display=None):\n",
    "        self.display = display\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def step(self, action):\n",
    "        #self.state = self.env.generate_number()\n",
    "        #self.env.display()\n",
    "        #print(action)\n",
    "        #self.placement = self.env.placement\n",
    "        self.next_state, self.reward, self.done= self.env.step(action)\n",
    "        #self.info = 0\n",
    "        #print(self.reward)\n",
    "        self.info = { 'pnl':1, 'nav':1, 'costs':1 }\n",
    "        #self.next_state = self.next_state.tolist()\n",
    "        \n",
    "        #if self.done:\n",
    "            #print(\"total pips\")\n",
    "            #print(np.sum(self.total_pips))\n",
    "            #print(len(self.total_pips))\n",
    "            #self.starter += 1\n",
    "            #pass\n",
    "        return self.next_state, self.reward, self.done, self.info\n",
    "\n",
    "    def step_async(self, action):\n",
    "        #self.state = self.env.generate_number()\n",
    "        #self.env.display()\n",
    "        #print(action)\n",
    "        #self.placement = self.env.placement\n",
    "        self.next_state, self.reward, self.done= self.env.step(action)\n",
    "        #self.info = 0\n",
    "        #print(self.reward)\n",
    "        self.info = { 'pnl':1, 'nav':1, 'costs':1 }\n",
    "        #self.next_state = self.next_state.tolist()\n",
    "        \n",
    "        #if self.done:\n",
    "            #print(\"total pips\")\n",
    "            #print(np.sum(self.total_pips))\n",
    "            #print(len(self.total_pips))\n",
    "            #self.starter += 1\n",
    "            #pass\n",
    "        return self.next_state, self.reward, self.done, self.info\n",
    "\n",
    "    def step_wait(self):\n",
    "        #self.state = self.env.generate_number()\n",
    "        #self.env.display()\n",
    "        #print(action)\n",
    "        #self.placement = self.env.placement\n",
    "        self.next_state, self.reward, self.done= self.env.step(action)\n",
    "        #self.info = 0\n",
    "        #print(self.reward)\n",
    "        self.info = { 'pnl':1, 'nav':1, 'costs':1 }\n",
    "        #self.next_state = self.next_state.tolist()\n",
    "        \n",
    "        #if self.done:\n",
    "            #print(\"total pips\")\n",
    "            #print(np.sum(self.total_pips))\n",
    "            #print(len(self.total_pips))\n",
    "            #self.starter += 1\n",
    "            #pass\n",
    "        return self.next_state, self.reward, self.done, self.info\n",
    "    \n",
    "\n",
    "    def reset(self):\n",
    "        \n",
    "        self.state = self.env.reset()\n",
    "        #self.reward = np.array([reward])\n",
    "        #self.state = self.state.tolist()\n",
    "        #self.state = np.array([self.state])\n",
    "        #self.steps_beyond_done = None\n",
    "        self.done = False\n",
    "        #self.done = np.array([self.done])\n",
    "        return self.state\n",
    "\n",
    "    def is_game_over(self):\n",
    "        pass\n",
    "        return\n",
    "\n",
    "    def render(self, mode=\"human\", close=False):\n",
    "        #self.env.display()\n",
    "        pass\n",
    "\n",
    "        return \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from stable_baselines3 import TD3\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "class SaveOnBestTrainingRewardCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Callback for saving a model (the check is done every ``check_freq`` steps)\n",
    "    based on the training reward (in practice, we recommend using ``EvalCallback``).\n",
    "\n",
    "    :param check_freq: (int)\n",
    "    :param log_dir: (str) Path to the folder where the model will be saved.\n",
    "      It must contains the file created by the ``Monitor`` wrapper.\n",
    "    :param verbose: (int)\n",
    "    \"\"\"\n",
    "    def __init__(self, check_freq: int, log_dir: str, verbose=1):\n",
    "        super(SaveOnBestTrainingRewardCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.log_dir = log_dir\n",
    "        self.save_path = os.path.join(log_dir, 'best_model')\n",
    "        self.best_mean_reward = -np.inf\n",
    "\n",
    "    def _init_callback(self) -> None:\n",
    "        # Create folder if needed\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "\n",
    "          # Retrieve training reward\n",
    "          x, y = ts2xy(load_results(self.log_dir), 'timesteps')\n",
    "          if len(x) > 0:\n",
    "              # Mean training reward over the last 100 episodes\n",
    "              mean_reward = np.mean(y[-100:])\n",
    "              if self.verbose > 0:\n",
    "                print(f\"Num timesteps: {self.num_timesteps}\")\n",
    "                print(f\"Best mean reward: {self.best_mean_reward:.2f} - Last mean reward per episode: {mean_reward:.2f}\")\n",
    "\n",
    "              # New best model, you could save the agent here\n",
    "              if mean_reward > self.best_mean_reward:\n",
    "                  self.best_mean_reward = mean_reward\n",
    "                  # Example for saving best model\n",
    "                  if self.verbose > 0:\n",
    "                    print(f\"Saving new best model to {self.save_path}.zip\")\n",
    "                  self.model.save(self.save_path)\n",
    "\n",
    "        return True\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33madaptationai\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "/home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages/IPython/html.py:12: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  warn(\"The `IPython.html` package has been deprecated since IPython 4.0. \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/adaptationai/flappy/runs/2nnzmeae\" target=\"_blank\">vivid-sunset-36</a></strong> to <a href=\"https://wandb.ai/adaptationai/flappy\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"flappy\")\n",
    "from wandb.integration.sb3 import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (0.12.4)\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.12.5-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 1.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from wandb) (2.8.2)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from wandb) (3.18.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: pathtools in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from wandb) (8.0.1)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from wandb) (1.0.1)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from wandb) (1.4.3)\n",
      "Requirement already satisfied: yaspin>=1.0.0 in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from wandb) (2.1.0)\n",
      "Requirement already satisfied: configparser>=3.8.1 in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from wandb) (5.0.2)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from wandb) (5.8.0)\n",
      "Requirement already satisfied: subprocess32>=3.5.3 in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from wandb) (3.5.4)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from wandb) (3.1.24)\n",
      "Requirement already satisfied: six>=1.13.0 in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from wandb) (1.16.0)\n",
      "Requirement already satisfied: PyYAML in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from wandb) (5.4.1)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from wandb) (2.26.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from GitPython>=1.0.0->wandb) (4.0.7)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2.0.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (3.2)\n",
      "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n",
      "Installing collected packages: wandb\n",
      "  Attempting uninstall: wandb\n",
      "    Found existing installation: wandb 0.12.4\n",
      "    Uninstalling wandb-0.12.4:\n",
      "      Successfully uninstalled wandb-0.12.4\n",
      "Successfully installed wandb-0.12.5\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from stable_baselines3.common.cmd_util import make_atari_env\n",
    "from sb3_contrib import QRDQN\n",
    "from stable_baselines3.common.vec_env import VecFrameStack ,DummyVecEnv, VecNormalize\n",
    "from stable_baselines3 import A2C, PPO, DQN\n",
    "import torch\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback, EveryNTimesteps\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "time.sleep(60)\n",
    "config = {\"policy_type\": \"CnnPolicy\", \"total_timesteps\": 1000000}\n",
    "experiment_name = f\"flappy_{int(time.time())}\"\n",
    "# Initialise a W&B run\n",
    "wandb.init(\n",
    "    name=experiment_name,\n",
    "    project=\"flappy\",\n",
    "    config=config,\n",
    "    sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
    "    monitor_gym=True,  # auto-upload the videos of agents playing the game\n",
    "    save_code=True,  # optional\n",
    ")\n",
    "# There already exists an environment generator\n",
    "# that will make and wrap atari environments correctly.\n",
    "# Here we are also multi-worker training (n_envs=4 => 4 environments)\n",
    "log_dir = \"./data/qrdqnnorewardscaling/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "env = Template_Gym()\n",
    "env = Monitor(env, log_dir)\n",
    "#env = Controller_Gym(env)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "#obs = env.reset()\n",
    "# It will check your custom environment and output additional warnings if needed\n",
    "#check_env(env)\n",
    "#env = VecFrameStack(env,4)\n",
    "#env = ScaledFloatFrame(env)\n",
    "#env = MaxAndSkipEnv(env, skip=1)\n",
    "#env = BufferWrapper(env, 2)\n",
    "#env = DummyVecEnv(env)\n",
    "#env2 = make_atari_env(env, n_envs=1, seed=0)\n",
    "#Frame-stacking with 4 frames\n",
    "#env = VecNormalize(env)\n",
    "env = VecFrameStack(env, n_stack=4)\n",
    "callback = SaveOnBestTrainingRewardCallback(check_freq=1000, log_dir=log_dir)\n",
    "checkpoint_on_event = CheckpointCallback(save_freq=1, save_path='./data/dqn2/')\n",
    "event_callback = EveryNTimesteps(n_steps=5000, callback=checkpoint_on_event)\n",
    "\n",
    "#model = QRDQN('CnnPolicy', env, verbose=1, tensorboard_log=\"./flappy2_tensorboard/\")\n",
    "model = QRDQN(config[\"policy_type\"], env, verbose=1, tensorboard_log=f\"runs/{experiment_name}\")\n",
    "#model = QRDQN.load(\"./data/qrdqn/best_model.zip\", env = env, tensorboard_log=\"./flappy2_tensorboard/\", learning_starts=25, learning_rate =0.00001)\n",
    "#env = model.get_env()\n",
    "# Add the WandbCallback \n",
    "model.learn(\n",
    "    total_timesteps=config[\"total_timesteps\"],\n",
    "    callback=WandbCallback(\n",
    "        gradient_save_freq=100,\n",
    "        model_save_freq=1000,\n",
    "        model_save_path=f\"models/{experiment_name}\",\n",
    "    ),\n",
    ")\n",
    "#model.learn(total_timesteps=1000000, callback=event_callback)\n",
    "#model.save_replay_buffer(\"qrdgn_flappy_new_replay_noreward\")\n",
    "#for i in range(100):\n",
    "    #try:\n",
    "        #model.load(\"qrdgn_flappy_2fs\"+str(i-1))\n",
    "        #model.load_replay_buffer(\"qrdgn_flappy_new_replay_noreward\")\n",
    "    #except:\n",
    "        #print(\"cnat load\")\n",
    "    #model.learn(total_timesteps=250000, reset_num_timesteps=False, callback=event_callback)\n",
    "    #model.save(\"qrdgn_flappy_noreward\"+str(i))\n",
    "    #model.save_replay_buffer(\"qrdgn_flappy_new_replay_noreward\")\n",
    "    \n",
    "\n",
    "#obs = env.reset()\n",
    "#while True:\n",
    "    #action, _states = model.predict(obs)\n",
    "    #print(model.predict(obs))\n",
    "    #print(model.predict(obs[0]))\n",
    "    #obs, rewards, dones, info = env.step(action)\n",
    "    #env.render()\n",
    "\n",
    "#model.save(\"ppo_flappy_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "def linear_schedule(initial_value: Union[float, str]) -> Callable[[float], float]:\n",
    "    \"\"\"\n",
    "    Linear learning rate schedule.\n",
    "    :param initial_value: (float or str)\n",
    "    :return: (function)\n",
    "    \"\"\"\n",
    "    if isinstance(initial_value, str):\n",
    "        initial_value = float(initial_value)\n",
    "\n",
    "    def func(progress_remaining: float) -> float:\n",
    "        \"\"\"\n",
    "        Progress will decrease from 1 (beginning) to 0\n",
    "        :param progress_remaining: (float)\n",
    "        :return: (float)\n",
    "        \"\"\"\n",
    "        return progress_remaining * initial_value\n",
    "\n",
    "    return func\n",
    "\n",
    "\n",
    "def hyper_ppo2():\n",
    "        return {\n",
    "            'n_steps': int(128),\n",
    "            'learning_rate': linear_schedule(2.5e-4),\n",
    "            'ent_coef': float(0.01),\n",
    "            'clip_range': linear_schedule(0.1),\n",
    "            'n_epochs': int(4),\n",
    "            'batch_size': int(256),\n",
    "            'vf_coef': float(0.5),\n",
    "            #'lam': trial.suggest_uniform('lam', 0.8, 1.)\n",
    "        }\n",
    "\n",
    "model_params = hyper_ppo2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "log_dir = \"./data/flappyppo/\"\n",
    "def make_env(env_id, rank, seed=0):\n",
    "    \"\"\"\n",
    "    Utility function for multiprocessed env.\n",
    "\n",
    "    :param env_id: (str) the environment ID\n",
    "    :param num_env: (int) the number of environments you wish to have in subprocesses\n",
    "    :param seed: (int) the inital seed for RNG\n",
    "    :param rank: (int) index of the subprocess\n",
    "    \"\"\"\n",
    "    def _init():\n",
    "        log_dir = \"./data/flappyppo/\"\n",
    "        env = Template_Gym()\n",
    "        env = Monitor(env, log_dir)\n",
    "        env.seed(seed + rank)\n",
    "        return env\n",
    "    set_random_seed(seed)\n",
    "    return _init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33madaptationai\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/adaptationai/flappy/runs/ta8kszdq\" target=\"_blank\">generous-bush-100</a></strong> to <a href=\"https://wandb.ai/adaptationai/flappy\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"flappy\")\n",
    "from wandb.integration.sb3 import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ta8kszdq) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 21247... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">generous-bush-100</strong>: <a href=\"https://wandb.ai/adaptationai/flappy/runs/ta8kszdq\" target=\"_blank\">https://wandb.ai/adaptationai/flappy/runs/ta8kszdq</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211023_181616-ta8kszdq/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:ta8kszdq). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/adaptationai/flappy/runs/xsrtq1x0\" target=\"_blank\">flappy_1634975179</a></strong> to <a href=\"https://wandb.ai/adaptationai/flappy\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkServerProcess-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py\", line 24, in _worker\n",
      "    env = env_fn_wrapper.var()\n",
      "  File \"/tmp/ipykernel_21159/4050025601.py\", line 14, in _init\n",
      "NameError: name 'Template_Gym' is not defined\n",
      "Process ForkServerProcess-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py\", line 24, in _worker\n",
      "    env = env_fn_wrapper.var()\n",
      "  File \"/tmp/ipykernel_21159/4050025601.py\", line 14, in _init\n",
      "NameError: name 'Template_Gym' is not defined\n",
      "Process ForkServerProcess-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py\", line 24, in _worker\n",
      "    env = env_fn_wrapper.var()\n",
      "  File \"/tmp/ipykernel_21159/4050025601.py\", line 14, in _init\n",
      "NameError: name 'Template_Gym' is not defined\n",
      "Process ForkServerProcess-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py\", line 24, in _worker\n",
      "    env = env_fn_wrapper.var()\n",
      "  File \"/tmp/ipykernel_21159/4050025601.py\", line 14, in _init\n",
      "NameError: name 'Template_Gym' is not defined\n"
     ]
    },
    {
     "ename": "ConnectionResetError",
     "evalue": "[Errno 104] Connection reset by peer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21159/14492786.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mnum_cpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;31m# # Number of processes to use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# Create the vectorized environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSubprocVecEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmake_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_cpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVecFrameStack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_stack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m#env = Monitor(env, log_dir)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/shamanai/lib/python3.8/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, env_fns, start_method)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremotes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get_spaces\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mobservation_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremotes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0mVecEnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/shamanai/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/shamanai/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/shamanai/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionResetError\u001b[0m: [Errno 104] Connection reset by peer"
     ]
    }
   ],
   "source": [
    "#from stable_baselines3.common.cmd_util import make_atari_env\n",
    "from sb3_contrib import QRDQN\n",
    "from stable_baselines3.common.vec_env import VecFrameStack ,DummyVecEnv, VecNormalize, SubprocVecEnv\n",
    "from stable_baselines3 import A2C, PPO, DQN\n",
    "import torch\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback, EveryNTimesteps\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "config = {\"policy_type\": \"CnnPolicy\", \"total_timesteps\": 4000000}\n",
    "experiment_name = f\"flappy_{int(time.time())}\"\n",
    "# Initialise a W&B run\n",
    "wandb.init(\n",
    "    name=experiment_name,\n",
    "    project=\"flappy\",\n",
    "    config=config,\n",
    "    sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
    "    monitor_gym=True,  # auto-upload the videos of agents playing the game\n",
    "    save_code=True,  # optional\n",
    ")\n",
    "# There already exists an environment generator\n",
    "# that will make and wrap atari environments correctly.\n",
    "# Here we are also multi-worker training (n_envs=4 => 4 environments)\n",
    "log_dir = \"./data/flappyppo2/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "time.sleep(10)\n",
    "num_e = 1\n",
    "# There already exists an environment generator\n",
    "# that will make and wrap atari environments correctly.\n",
    "# Here we are also multi-worker training (n_envs=4 => 4 environments)\n",
    "\n",
    "#env = Template_Gym()\n",
    "#env = Monitor(env, log_dir)\n",
    "#env = DummyVecEnv([lambda: env])\n",
    "#env = Template_Gym()\n",
    "env_id = \"flappy\"\n",
    "num_cpu = 4 # # Number of processes to use\n",
    "    # Create the vectorized environment\n",
    "env = SubprocVecEnv([make_env(env_id, i) for i in range(num_cpu)])\n",
    "env = VecFrameStack(env, n_stack=4)\n",
    "#env = Monitor(env, log_dir)\n",
    "#env = Controller_Gym(env)\n",
    "#env = DummyVecEnv([lambda: env])\n",
    "callback = SaveOnBestTrainingRewardCallback(check_freq=1000, log_dir=log_dir)\n",
    "checkpoint_on_event = CheckpointCallback(save_freq=1, save_path='./data/ppo2/')\n",
    "event_callback = EveryNTimesteps(n_steps=5000, callback=checkpoint_on_event)\n",
    "model = PPO(config[\"policy_type\"], env, verbose=1, tensorboard_log=f\"runs/{experiment_name}\")\n",
    "model.learn(\n",
    "    total_timesteps=config[\"total_timesteps\"],\n",
    "    callback=WandbCallback(\n",
    "        gradient_save_freq=100,\n",
    "        model_save_freq=1000,\n",
    "        model_save_path=f\"models/{experiment_name}\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "#model.learn(total_timesteps=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (4.0.0)\n",
      "Requirement already satisfied: urllib3[secure]~=1.26 in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from selenium) (1.26.7)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: trio~=0.17 in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from selenium) (0.19.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from trio~=0.17->selenium) (21.2.0)\n",
      "Requirement already satisfied: sortedcontainers in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: sniffio in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: idna in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from trio~=0.17->selenium) (3.2)\n",
      "Requirement already satisfied: outcome in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from trio~=0.17->selenium) (1.1.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: wsproto>=0.14 in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from trio-websocket~=0.9->selenium) (1.0.0)\n",
      "Requirement already satisfied: certifi in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from urllib3[secure]~=1.26->selenium) (2021.5.30)\n",
      "Requirement already satisfied: cryptography>=1.3.4 in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from urllib3[secure]~=1.26->selenium) (35.0.0)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14 in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from urllib3[secure]~=1.26->selenium) (21.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from cryptography>=1.3.4->urllib3[secure]~=1.26->selenium) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure]~=1.26->selenium) (2.20)\n",
      "Requirement already satisfied: six>=1.5.2 in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from pyOpenSSL>=0.14->urllib3[secure]~=1.26->selenium) (1.16.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /home/adaptationai/anaconda3/envs/shamanai/lib/python3.8/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U selenium"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "45f6805382db68bf64fff698ab04f8fc19de098f2db98374d9f65f050e71ecd1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
