{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Table of Contents:\r\n",
    "Step1: Image collection and Labelling\r\n",
    "Step2: Installation of the required package\r\n",
    "Step3: Custom image augmentation\r\n",
    "Step4: Model Training\r\n",
    "Step5: Model saving, loading, and predicting"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step1: Image collection and labeling:\r\n",
    "The first step of any object detection model is collecting images and performing annotation. For this project, I have downloaded 50 ‘Maruti Car Images’ from google image. There is a package called simple_image_download which is used for automatic image download. Feel free to use the following code:\r\n",
    "\r\n",
    "With this code, we will get 50 downloaded images in our ‘Maruti Car’ folder of the working directory. Feel free to change the number of images to as many as you want. After that, we will randomly split images into two parts i.e. Train (35 images) and Test(15 images)\r\n",
    "\r\n",
    "The next job is labeling the images. There are various image annotation tool is available. For this project, I have used MAKESENSE.AI. It’s a free online tool for labeling. No installation process is required. We can open it using the browser only. Using the link, I dropped my car images and did annotation for Train and Validation datasets separately.\r\n",
    "\r\n",
    "Now, we can export the annotation in XML format as ‘Detecto’ supports it. Then we have placed XML files of train and validation images in the Train and validation folder respectively. So the folder tree looks like this:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from simple_image_download import simple_image_download as simp\r\n",
    "response = simp.simple_image_download\r\n",
    "lst=['Maruti car']\r\n",
    "for rep in lst:\r\n",
    " response().download(rep, 50)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "##MAKESENSE.AI"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step2: Installation of the required packages:\r\n",
    "As it is already mentioned that ‘Detecto’ is built on top of the PyTorch, we need to first install PyTorch. I have used Google Colab for this project. Then we need to check whether we have the support of GPU or not using the following code:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\r\n",
    "print(torch.cude.is_available())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "If the print is ‘True’, it means you can use GPU. If it is ‘False’, please change the ‘Hardware Accelerator’ of the Notebook Setting to ‘GPU’. Now, your system is ready with the requisition to install ‘Detecto’. Use the following magic code to install it."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install detecto"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once it’s done, let’s import the libraries using the following code:\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from detecto import core, utils, visualize\r\n",
    "from detecto.visualize import show_labeled_image, plot_prediction_grid\r\n",
    "from torchvision import transforms\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step3: Custom image augmentation:\r\n",
    "Image augmentation is the process of artificially expanding data by creating a modified version of images. Detecto has an inbuilt function to do custom transform by applying to resize, flip, and saturation augmentation. Please, use the following code for augmenting the image dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "custom_transforms = transforms.Compose([\r\n",
    "transforms.ToPILImage(),\r\n",
    "transforms.Resize(900),\r\n",
    "transforms.RandomHorizontalFlip(0.5),\r\n",
    "transforms.ColorJitter(saturation=0.2),\r\n",
    "transforms.ToTensor(),\r\n",
    "utils.normalize_transform(),\r\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step4: Model Training:\r\n",
    "Now, we have come to that most awaited step i.e. Model Training. Here, magic happens in Five lines of code."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Train_dataset=core.Dataset('Train/',transform=custom_transforms)#L1\r\n",
    "Test_dataset = core.Dataset('Test/')#L2\r\n",
    "loader=core.DataLoader(Train_dataset, batch_size=2, shuffle=True)#L3\r\n",
    "model = core.Model(['Wheel', 'Head Light'])#L4\r\n",
    "losses = model.fit(loader, Test_dataset, epochs=25, lr_step_size=5, learning_rate=0.001, verbose=True)#L5"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the first two lines of code(L1 & L2), we have assigned Train and Test dataset. In L3, we have created DataLoader over our dataset. It helps define how we batch and feed our images into the model for training. Feel free to experiment by changing ‘batch_size’.\r\n",
    "\r\n",
    "Now, it’s time to mention the ‘Labels’ or ‘classes’ which are made in L4. Finally, model training will be started via ‘model.fit’ in L5. Here, we can play with different options such as epochs, lr_step_size, and learning rate’. The default model is Faster R-CNN ResNet-50 FPN. We have fine-tuned this model for our custom dataset.\r\n",
    "\r\n",
    "Now, we can look at the loss function using the following code:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.plot(losses)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step5: Model saving, loading, and predicting:\r\n",
    "Once we are satisfied with a model loss, we need to save the model for future reference. So that we can load it as and when required. Use the following code for saving and loading."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.save('model_weights.pth')\r\n",
    "model = core.Model.load('model_weights.pth', ['Wheel', 'Head Light'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "After loading the model, we want to use it for prediction. Let’s use it for one observation from the Test folder and plot the image with a bounding box. Here, the prediction format is labels, boxes, and scores."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "image = utils.read_image('Test/Maruti car_27.jpeg') \r\n",
    "predictions = model.predict(image)\r\n",
    "labels, boxes, scores = predictions\r\n",
    "show_labeled_image(image, boxes, labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are many unwanted bounding boxes in the above picture. So, we have to remove them. The simplest way to solve the issue is by providing a threshold on the score. For this project, I have put the threshold as 0.6 for both classes. I came to this point through different trials and errors. Use the following code to set up the threshold for bounding boxes and plotting them."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "thresh=0.6\r\n",
    "filtered_indices=np.where(scores>thresh)\r\n",
    "filtered_scores=scores[filtered_indices]\r\n",
    "filtered_boxes=boxes[filtered_indices]\r\n",
    "num_list = filtered_indices[0].tolist()\r\n",
    "filtered_labels = [labels[i] for i in num_list]\r\n",
    "show_labeled_image(image, filtered_boxes, filtered_labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, we can see the final output. And yes, it is quite impressive. So, this the end of the project. Let us know your opinion after using this one for your custom dataset.\r\n",
    "\r\n",
    "Happy learnings !!!!"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}